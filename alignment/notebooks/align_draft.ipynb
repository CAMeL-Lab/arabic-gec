{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5370aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "from aligner_word import Aligner\n",
    "import re\n",
    "from camel_tools.utils.normalize import (\n",
    "    normalize_alef_ar,\n",
    "    normalize_alef_maksura_ar,\n",
    "    normalize_teh_marbuta_ar\n",
    ")\n",
    "aligner = Aligner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path) as f:\n",
    "        return [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc35080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_alignment(path):\n",
    "    example = []\n",
    "    examples = []\n",
    "    with open(path, mode='r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data = line.split('\\t')\n",
    "                ex = data[:-1] + [eval(data[-1])]\n",
    "                example.append(ex)\n",
    "            else:\n",
    "                examples.append(example)\n",
    "                example = []\n",
    "        \n",
    "        # adding the last example\n",
    "        if example:\n",
    "            examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c53a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Range:\n",
    "    def __init__(self, start, end, ops):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.ops = ops\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.to_dict())\n",
    "\n",
    "    def to_json_str(self):\n",
    "        return json.dumps(self.to_dict(), indent=2, ensure_ascii=False)\n",
    "\n",
    "    def to_dict(self):\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "def sort_range(v):\n",
    "    span = v[-1]\n",
    "    return [span[0], span[0]] if span[1] == None else [span[1], span[1]]\n",
    "\n",
    "def capture_bug(alignment):\n",
    "    i = 0\n",
    "    found_span = False\n",
    "    buggy_span = []\n",
    "    \n",
    "    while i < len(alignment):\n",
    "        potential_buggy = {}\n",
    "        start_idx = i - 1\n",
    "        \n",
    "        # if we see a sequence of deletes, replaces, and inserts --> this is a potential bug\n",
    "        while i < len(alignment) and ('DELETE' in alignment[i][2] or 'REPLACE' in alignment[i][2] or\n",
    "                                      'INSERT' in alignment[i][1]):\n",
    "        \n",
    "            potential_buggy[i] = alignment[i]\n",
    "            i += 1\n",
    "        \n",
    "        if len(potential_buggy) > 1:\n",
    "\n",
    "            # save the start and end anchors and the sequence of edits\n",
    "            buggy_span.append(Range(start_idx, i, potential_buggy))\n",
    "#             buggy_span.append(Range(start_idx, i, dict(sorted(potential_buggy.items(),\n",
    "#                                                               key=lambda x: sort_range(x[1])))))\n",
    "    \n",
    "        elif len(potential_buggy) == 0:\n",
    "            i += 1\n",
    "            \n",
    "    return buggy_span\n",
    "\n",
    "def perform_align(inputs):\n",
    "    return inputs[0], aligner.align(*inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c2e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "599607db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_str(s):\n",
    "    norm_s = normalize_alef_ar(s)\n",
    "    norm_s = normalize_alef_maksura_ar(norm_s)\n",
    "    norm_s = normalize_teh_marbuta_ar(norm_s)\n",
    "    return norm_s\n",
    "\n",
    "def clean_potential_merge(src, tgt):\n",
    "    i = 0\n",
    "    src_ = normalize_str(' '.join(src)).split()\n",
    "    tgt_ = normalize_str(' '.join(tgt)).split()\n",
    "    \n",
    "    pairwise = [''.join(x) for x in list(zip(src_, src_[1:]))]\n",
    "    new_src = []\n",
    "    \n",
    "    while i < len(pairwise):\n",
    "\n",
    "        if pairwise[i] in tgt_:\n",
    "            new_src.append(pairwise[i])\n",
    "            i += 2\n",
    "        else:\n",
    "            new_src.append(src[i])\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "    while i < len(src):\n",
    "        new_src.append(src[i])\n",
    "        i += 1\n",
    "    \n",
    "    return new_src\n",
    "\n",
    "def construct_src_tgt(bug):\n",
    "    src = []\n",
    "    tgt = []\n",
    "    for v in bug.ops.values():\n",
    "\n",
    "        if v[2] == 'DELETE':\n",
    "            src.append(v[0])\n",
    "\n",
    "        elif v[1] == 'INSERT':\n",
    "            tgt.append(v[0])\n",
    "\n",
    "        elif v[2] == 'REPLACE':\n",
    "            src.append(v[0])\n",
    "            tgt.append(v[1])\n",
    "\n",
    "    src = clean_potential_merge(src, tgt)\n",
    "    \n",
    "    return ' S '.join(src), ' S '.join(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb07eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_alignment(src_align, tgt_align):\n",
    "    clean_src = [x.strip() for x in src_align]\n",
    "    clean_tgt = [x.strip() for x in tgt_align]\n",
    "        \n",
    "#     print(clean_src)\n",
    "#     print(clean_tgt)\n",
    "#     clean_src = []\n",
    "#     clean_tgt = []\n",
    "    \n",
    "#     # cleaning merges\n",
    "#     is_merge = False\n",
    "#     for x, y in zip(src, tgt):\n",
    "# #         import pdb; pdb.set_trace()\n",
    "#         if x == 'S' and y == '':\n",
    "#             is_merge = True\n",
    "#         else:\n",
    "#             if is_merge:\n",
    "#                 clean_src[-1] = clean_src[-1] + ' ' + x\n",
    "#                 clean_tgt[-1] = clean_tgt[-1] + y\n",
    "#                 is_merge = False\n",
    "#             else:\n",
    "#                 clean_src.append(x)\n",
    "#                 clean_tgt.append(y)\n",
    "    \n",
    "#     # merging target if needed\n",
    "    pairwise = list(zip(clean_tgt, clean_tgt[1:]))\n",
    "    i = 0\n",
    "    clean_tgt_ = []\n",
    "\n",
    "    while i < len(pairwise):\n",
    "        element = pairwise[i]\n",
    "\n",
    "        if element[0] != 'S' and element[1] != 'S' and element[0] != '' and element[1] != '':\n",
    "            clean_tgt_.append(element[0] + element[1])\n",
    "            i += 2\n",
    "        else:\n",
    "            clean_tgt_.append(clean_tgt[i])\n",
    "            i += 1\n",
    "        \n",
    "        \n",
    "    while i < len(clean_tgt):\n",
    "        clean_tgt_.append(clean_tgt[i])\n",
    "        i += 1\n",
    "    \n",
    "    print(clean_src)\n",
    "    print(clean_tgt_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e763cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_alignment = read_alignment('/scratch/ba63/gec/data/ZAEBUC-v1.0/data/ar/dev/dev.alignment')\n",
    "src = read_data('/scratch/ba63/gec/data/ZAEBUC-v1.0/data/ar/dev/dev.sent.raw.pnx.tok')\n",
    "cor = read_data('/scratch/ba63/gec/data/ZAEBUC-v1.0/data/ar/dev/dev.sent.cor.pnx.tok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3d5b573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_alignment = read_alignment('/scratch/ba63/gec/data/QALB-0.9.1-Dec03-2021-SharedTasks/data'\\\n",
    "#                                  '/2014/tune/tune.alignment')\n",
    "# src = read_data('/scratch/ba63/gec/data/QALB-0.9.1-Dec03-2021-SharedTasks/data/'\\\n",
    "#                 '2014/tune/QALB-2014-L1-Tune.sent.no_ids.clean')\n",
    "# cor = read_data('/scratch/ba63/gec/data/QALB-0.9.1-Dec03-2021-SharedTasks/data/'\\\n",
    "#                 '2014/tune/QALB-2014-L1-Tune.cor.no_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "813d3e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0, 'end': 4, 'ops': {1: ['الجتماعي', 'الاجتماعي', 'REPLACE', (2, 2)], 2: ['هي', '', 'DELETE', (3, None)], 3: ['الان', 'الآن', 'REPLACE', (4, 3)]}},\n",
       " {'start': 4, 'end': 7, 'ops': {5: ['احدى', 'أحد', 'REPLACE', (6, 5)], 6: ['اكثر', 'أكثر', 'REPLACE', (7, 6)]}},\n",
       " {'start': 14, 'end': 17, 'ops': {15: ['اأجتماعي', 'الاجتماعي', 'REPLACE', (16, 15)], 16: ['لهو', 'له', 'REPLACE', (17, 16)]}},\n",
       " {'start': 21, 'end': 24, 'ops': {22: ['و', '', 'DELETE', (23, None)], 23: ['الفرد', 'والفرد', 'REPLACE', (24, 22)]}},\n",
       " {'start': 28, 'end': 33, 'ops': {29: ['ال', 'الوحدة', 'REPLACE', (30, 28)], 30: ['حده', '', 'DELETE', (31, None)], 31: ['و', '', 'DELETE', (32, None)], 32: ['الكآبه', 'والكآبة', 'REPLACE', (33, 29)]}},\n",
       " {'start': 33, 'end': 36, 'ops': {34: ['و', '', 'DELETE', (35, None)], 35: ['في', 'وفي', 'REPLACE', (36, 31)]}},\n",
       " {'start': 46, 'end': 53, 'ops': {47: ['العائله', 'العائلة', 'REPLACE', (48, 43)], 48: ['و', '', 'DELETE', (49, None)], 49: ['الفرد', 'والفرد', 'REPLACE', (50, 44)], 50: ['و', '', 'DELETE', (51, None)], 51: ['بين', 'وبين', 'REPLACE', (52, 45)], 52: ['الاشخاص', 'الأشخاص', 'REPLACE', (53, 46)]}}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "86068caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = [', لوكان'.split()]\n",
    "# tgt = ['. لو كان']\n",
    "# inputs = list(zip(src, tgt))\n",
    "# perform_align(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "190ee07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الجتماعي S هي S الان\n",
      "الاجتماعي S الآن\n",
      "========\n",
      "['الجتماعي', 'S', 'هي', 'S', 'الان']\n",
      "['الاجتماع', '', 'ي', ' S ', 'الآن']\n",
      "========\n",
      "['الجتماعي', 'S', 'هي', 'S', 'الان']\n",
      "['الاجتماع', '', 'ي', 'S', 'الآن']\n",
      "\n",
      "احدى S اكثر\n",
      "أحد S أكثر\n",
      "========\n",
      "['احدى', 'S', 'اكثر']\n",
      "['أحد', ' S ', 'أكثر']\n",
      "========\n",
      "['احدى', 'S', 'اكثر']\n",
      "['أحد', 'S', 'أكثر']\n",
      "\n",
      "اأجتماعي S لهو\n",
      "الاجتماعي S له\n",
      "========\n",
      "['اأجتماعي', 'S', 'لهو']\n",
      "['الاجتماعي ', 'S', ' له']\n",
      "========\n",
      "['اأجتماعي', 'S', 'لهو']\n",
      "['الاجتماعي', 'S', 'له']\n",
      "\n",
      "والفرد\n",
      "والفرد\n",
      "========\n",
      "['والفرد']\n",
      "['والفرد']\n",
      "========\n",
      "['والفرد']\n",
      "['والفرد']\n",
      "\n",
      "ال S حده S والكابه\n",
      "الوحدة S والكآبة\n",
      "========\n",
      "['ال', 'S', 'حده', 'S', 'والكابه']\n",
      "['ال', 'و', 'حدة', ' S ', 'والكآبة']\n",
      "========\n",
      "['ال', 'S', 'حده', 'S', 'والكابه']\n",
      "['الو', 'حدة', 'S', 'والكآبة']\n",
      "\n",
      "وفي\n",
      "وفي\n",
      "========\n",
      "['وفي']\n",
      "['وفي']\n",
      "========\n",
      "['وفي']\n",
      "['وفي']\n",
      "\n",
      "العائله S والفرد S وبين S الاشخاص\n",
      "العائلة S والفرد S وبين S الأشخاص\n",
      "========\n",
      "['العائله', 'S', 'والفرد', 'S', 'وبين', 'S', 'الاشخاص']\n",
      "['العائلة', ' S ', 'والفرد', ' S ', 'وبين', ' S ', 'الأشخاص']\n",
      "========\n",
      "['العائله', 'S', 'والفرد', 'S', 'وبين', 'S', 'الاشخاص']\n",
      "['العائلة', 'S', 'والفرد', 'S', 'وبين', 'S', 'الأشخاص']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bug_ex = capture_bug(basic_alignment[3])\n",
    "for bug in bug_ex:\n",
    "    src, tgt = construct_src_tgt(bug)\n",
    "    inputs = list(zip([src.split()], [tgt]))\n",
    "    test_x, test_y = perform_align(inputs[0])\n",
    "    \n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    print('========')\n",
    "    print(test_x)\n",
    "    print(test_y)\n",
    "    print('========')\n",
    "    clean_alignment(test_x, test_y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b0abc4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", S ايضا\n",
      ". S أيضا\n"
     ]
    }
   ],
   "source": [
    "print(src)\n",
    "print(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "36fb65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_x)\n",
    "# print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cfefa137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['والمجتمع']\n",
      "['والمجتمع S .']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87912fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4879f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (misc)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
