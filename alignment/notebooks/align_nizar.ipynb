{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9fb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "from aligner_word import Aligner\n",
    "import re\n",
    "import string\n",
    "from camel_tools.utils.charsets import UNICODE_PUNCT_SYMBOL_CHARSET\n",
    "from camel_tools.utils.normalize import (\n",
    "    normalize_alef_ar,\n",
    "    normalize_alef_maksura_ar,\n",
    "    normalize_teh_marbuta_ar\n",
    ")\n",
    "import editdistance\n",
    "PUNCS = string.punctuation + ''.join(list(UNICODE_PUNCT_SYMBOL_CHARSET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ea99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"ألتحق بكلية الشريعة أنا طالب في جامعة الإمام محمد بن سعود الاسلامية الآن أدرس في تعليم اللغة العربية المستوى الرابع . وهذا الفصل آخر الفصل في المعهد . انتهى هذا الفصل ندخل إلى دبلوم يحتاج إلى سنة كاملة . أي بعد سنة واحدة ندخل الكلية . إن شاء الله سأختار إلى كلية الشريعة لأسباب كثيرة وأتخلص ما يلي : 1 - كلية الشريعة كاملة وشاملة تشمل الموضوعات كثيرة مثل : الفرائض والفقه وأصول الفقه وقواعد اللغة العربية والتوحيد والتفسير إلخ . وهذه المعلومات تدرس في كلية الشريعة إن شاء الله سأستفيد منها كثيرا 2 - وضع الدولة : من المعلوم أن الصين دولة الكفار كثير من المسلمين يتأثر ببوذية كثيرا . ووضعوا قبور الأولياء والصالحين بناء جميلة ليدعو إليه ويوف إليه تبرك به ويستعان به وهذه الخرافات والبدع أزيلها بالطريق الصحيح . وهذه الطرق الصحيح ندرس في الكلية . 3 - السبب النفسية : من بداية دراسة اللغة العربية والدينية أنا أحب مواد الشريعة من مواد أخرى . دائما أقرأ كتب الشرعية .\"\n",
    "y = \"ألتحق بكلية الشريعة أنا طالب في جامعة الإمام محمد بن سعود الاسلامية الآن أدرس في تعليم اللغة العربية المستوى الرابع . وهذا الفصل آخر الفصل في المعهد . انتهى هذا الفصل ندخل إلى دبلوم يحتاج إلى سنة كاملة . أي بعد سنة واحدة ندخل الكلية . إن شاء الله سأختار إلى كلية الشريعة لأسباب كثيرة وأتخلص ما يلي : 1 - كلية الشريعة كاملة وشاملة تشمل الموضوعات كثيرة مثل : الفرائض والفقه وأصول الفقه وقواعد اللغة العربية والتوحيد والتفسير إلخ . وهذه المعلومات تدرس في كلية الشريعة إن شاء الله سأستفيد منها كثيرا 2 - وضع الدولة : من المعلوم أن الصين دولة الكفار كثير من المسلمين يتأثر ببوذية كثيرا . ووضعوا قبور الأولياء والصالحين بناء جميلة ليدعو إليه ويوف إليه تبرك به ويستعان به وهذه الخرافات والبدع أزيلها بالطريق الصحيح . وهذه الطرق الصحيح ندرس في الكلية .   3 - السبب النفسية : من بداية دراسة اللغة العربية والدينية أنا أحب مواد الشريعة من مواد أخرى . دائما أقرأ كتب الشرعية .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4d581f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.split() == x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba5bb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b6a019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe1d4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ألتحق', 'بكلية', 'الشريعة', 'أنا', 'طالب', 'في', 'جامعة', 'الإمام', 'محمد', 'بن', 'سعود', 'الاسلامية', 'الآن', 'أدرس', 'في', 'تعليم', 'اللغة', 'العربية', 'المستوى', 'الرابع', '.', 'وهذا', 'الفصل', 'آخر', 'الفصل', 'في', 'المعهد', '.', 'انتهى', 'هذا', 'الفصل', 'ندخل', 'إلى', 'دبلوم', 'يحتاج', 'إلى', 'سنة', 'كاملة', '.', 'أي', 'بعد', 'سنة', 'واحدة', 'ندخل', 'الكلية', '.', 'إن', 'شاء', 'الله', 'سأختار', 'إلى', 'كلية', 'الشريعة', 'لأسباب', 'كثيرة', 'وأتخلص', 'ما', 'يلي', ':', '1', '-', 'كلية', 'الشريعة', 'كاملة', 'وشاملة', 'تشمل', 'الموضوعات', 'كثيرة', 'مثل', ':', 'الفرائض', 'والفقه', 'وأصول', 'الفقه', 'وقواعد', 'اللغة', 'العربية', 'والتوحيد', 'والتفسير', 'إلخ', '.', 'وهذه', 'المعلومات', 'تدرس', 'في', 'كلية', 'الشريعة', 'إن', 'شاء', 'الله', 'سأستفيد', 'منها', 'كثيرا', '2', '-', 'وضع', 'الدولة', ':', 'من', 'المعلوم', 'أن', 'الصين', 'دولة', 'الكفار', 'كثير', 'من', 'المسلمين', 'يتأثر', 'ببوذية', 'كثيرا', '.', 'ووضعوا', 'قبور', 'الأولياء', 'والصالحين', 'بناء', 'جميلة', 'ليدعو', 'إليه', 'ويوف', 'إليه', 'تبرك', 'به', 'ويستعان', 'به', 'وهذه', 'الخرافات', 'والبدع', 'أزيلها', 'بالطريق', 'الصحيح', '.', 'وهذه', 'الطرق', 'الصحيح', 'ندرس', 'في', 'الكلية', '.', '3', '-', 'السبب', 'النفسية', ':', 'من', 'بداية', 'دراسة', 'اللغة', 'العربية', 'والدينية', 'أنا', 'أحب', 'مواد', 'الشريعة', 'من', 'مواد', 'أخرى', '.', 'دائما', 'أقرأ', 'كتب', 'الشرعية', '.']\n"
     ]
    }
   ],
   "source": [
    "print(x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b21d8080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6195e149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77992fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a2e82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path) as f:\n",
    "        return [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de9c333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_alignment(path):\n",
    "    example = []\n",
    "    examples = []\n",
    "    with open(path, mode='r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data = line.split('\\t')\n",
    "                ex = data[:-1] + [eval(data[-1])]\n",
    "                example.append(ex)\n",
    "            else:\n",
    "                examples.append(example)\n",
    "                example = []\n",
    "        \n",
    "        # adding the last example\n",
    "        if example:\n",
    "            examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0120a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Range:\n",
    "    def __init__(self, start, end, ops):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.ops = ops\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.to_dict())\n",
    "\n",
    "    def to_json_str(self):\n",
    "        return json.dumps(self.to_dict(), indent=2, ensure_ascii=False)\n",
    "\n",
    "    def to_dict(self):\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "def sort_range(v):\n",
    "    span = v[-1]\n",
    "    return [span[0], span[0]] if span[1] == None else [span[1], span[1]]\n",
    "\n",
    "def capture_bug(alignment):\n",
    "    i = 0\n",
    "    found_span = False\n",
    "    buggy_span = []\n",
    "    \n",
    "    while i < len(alignment):\n",
    "        potential_buggy = {}\n",
    "        start_idx = i - 1\n",
    "        \n",
    "        # if we see a sequence of deletes, replaces, and inserts --> this is a potential bug\n",
    "        while i < len(alignment) and ('DELETE' in alignment[i][2] or 'REPLACE' in alignment[i][2] or\n",
    "                                      'INSERT' in alignment[i][1]):\n",
    "        \n",
    "            potential_buggy[i] = alignment[i]\n",
    "            i += 1\n",
    "        \n",
    "        if len(potential_buggy) > 1:\n",
    "\n",
    "            # save the start and end anchors and the sequence of edits\n",
    "            buggy_span.append(Range(start_idx, i, potential_buggy))\n",
    "#             buggy_span.append(Range(start_idx, i, dict(sorted(potential_buggy.items(),\n",
    "#                                                               key=lambda x: sort_range(x[1])))))\n",
    "    \n",
    "        elif len(potential_buggy) == 0:\n",
    "            i += 1\n",
    "            \n",
    "    return buggy_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a5d2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_str(s):\n",
    "    norm_s = normalize_alef_ar(s)\n",
    "    norm_s = normalize_alef_maksura_ar(norm_s)\n",
    "    norm_s = normalize_teh_marbuta_ar(norm_s)\n",
    "    return norm_s\n",
    "\n",
    "def clean_potential_merge(src, tgt):\n",
    "    i = 0\n",
    "    src_ = normalize_str(' '.join(src)).split()\n",
    "    tgt_ = normalize_str(' '.join(tgt)).split()\n",
    "    \n",
    "    pairwise = [''.join(x) for x in list(zip(src_, src_[1:]))]\n",
    "    new_src = []\n",
    "    \n",
    "    while i < len(pairwise):\n",
    "\n",
    "        if pairwise[i] in tgt_:\n",
    "            new_src.append(pairwise[i])\n",
    "            i += 2\n",
    "        else:\n",
    "            new_src.append(src[i])\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "    while i < len(src):\n",
    "        new_src.append(src[i])\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    return new_src\n",
    "\n",
    "def construct_src_tgt(bug):\n",
    "    src = []\n",
    "    tgt = []\n",
    "    for v in bug.ops.values():\n",
    "\n",
    "        if v[2] == 'DELETE':\n",
    "            src.append(v[0])\n",
    "            tgt.append('NIL')\n",
    "\n",
    "        elif v[1] == 'INSERT':\n",
    "            src.append('NIL')\n",
    "            tgt.append(v[0])\n",
    "            \n",
    "        elif v[2] == 'REPLACE':\n",
    "            src.append(v[0])\n",
    "            tgt.append(v[1])\n",
    "    \n",
    "    return src, tgt\n",
    "\n",
    "def consruct_clean_src_tgt(align):\n",
    "    src_tokens = []\n",
    "    tgt_tokens = []\n",
    "\n",
    "    for x in align:\n",
    "        if x[1] != 'INSERT':\n",
    "            src_tokens.append(x[0])\n",
    "            tgt_tokens.append(x[1])\n",
    "        else:\n",
    "            src_tokens.append('')\n",
    "            tgt_tokens.append(x[0])\n",
    "    \n",
    "    return src_tokens, tgt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964b412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34bb4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_align(src, tgt):\n",
    "    assert len(src) == len(tgt)\n",
    "    visited = set()\n",
    "    basic_edit = get_edit(src, tgt) # get the basic edit between src and tgt\n",
    "    best_edit = {'src': src, 'tgt': tgt, 'edit': basic_edit}\n",
    "\n",
    "    best_src, best_tgt = src, tgt\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(src):\n",
    "        \n",
    "        if (src[i] == 'NIL' and tgt[i] != 'NIL'): # insert or a potential split\n",
    "            visited.add((i, src[i], tgt[i]))\n",
    "            prepend = is_split_merge(src, tgt, i, 'prepend', src_first=True)\n",
    "            append = is_split_merge(src, tgt, i, 'append', src_first=True)\n",
    "            best_edit = get_best_edit(best_edit, prepend, append)\n",
    "\n",
    "        \n",
    "        elif (src[i] != 'NIL' and tgt[i] == 'NIL'): # delete or a potential merge\n",
    "            visited.add((i, src[i], tgt[i]))\n",
    "            prepend = is_split_merge(tgt, src, i, 'prepend', src_first=False)\n",
    "            append = is_split_merge(tgt, src, i, 'append', src_first=False)\n",
    "            best_edit = get_best_edit(best_edit, prepend, append)\n",
    "        \n",
    "        \n",
    "        # rewind the index in case of a change\n",
    "        if best_edit['src'] != src or best_edit['tgt'] != tgt:\n",
    "            src, tgt = best_edit['src'], best_edit['tgt']\n",
    "            i = 0\n",
    "            continue\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return best_edit['src'], best_edit['tgt']\n",
    "        \n",
    "def is_split_merge(src, tgt, i, mode='prepend', src_first=False):\n",
    "    \n",
    "    plausible = False\n",
    "\n",
    "    if mode == 'prepend':\n",
    "        j = i - 1\n",
    "\n",
    "        while j >= 0 and tgt[j] == 'NIL': # find the latest non-NIL \n",
    "            j -= 1\n",
    "        \n",
    "        if j >= 0:\n",
    "            src_ = src[:i] + src[i + 1:]\n",
    "#             tgt_ = tgt[:j] + [tgt[j] + ' ' + tgt[i]] + tgt[i + 1:]\n",
    "            tgt_ = tgt[:j] + [tgt[j] + ' ' + tgt[i]] + [tgt[x] for x in range(j+1, len((tgt))) if x != i]\n",
    "\n",
    "            if len(src_) == len(tgt_):\n",
    "                edit_all = get_edit(src_, tgt_)\n",
    "                edit_no_space = get_edit(src_, [x.replace(' ','') for x in tgt_])\n",
    "                \n",
    "                edit = edit_no_space + 0.1 * (edit_all - edit_no_space)\n",
    "            \n",
    "                if src_first:\n",
    "                    # split on target\n",
    "                    return {'src': src_, 'tgt': tgt_,\n",
    "                            'edit': edit}\n",
    "                else:\n",
    "                    # merge on source\n",
    "                    return {'src': tgt_ , 'tgt': src_,\n",
    "                            'edit': edit}\n",
    "        \n",
    "        \n",
    "        if plausible == False:\n",
    "            if src_first:\n",
    "                return {'src': src, 'tgt': tgt, 'edit': get_edit(src, tgt)}\n",
    "            else:\n",
    "                return {'src': tgt, 'tgt': src, 'edit': get_edit(src, tgt)}\n",
    "    \n",
    "    elif mode == 'append': # find the first non-NIL\n",
    "        j = i + 1\n",
    "\n",
    "        while j < len(tgt) and tgt[j] == 'NIL':\n",
    "            j += 1\n",
    "        \n",
    "        if j < len(tgt):\n",
    "            src_ = src[:i] + src[i + 1:]\n",
    "#             tgt_ = tgt[:i] + [tgt[i] + ' ' + tgt[j]] + tgt[j + 1:]\n",
    "            tgt_ = tgt[:i] + [tgt[i] + ' ' + tgt[j]] + [tgt[x] for x in range(i+1, len((tgt))) if x != j]\n",
    "            \n",
    "    \n",
    "            if len(src_) == len(tgt_):\n",
    "                edit_all = get_edit(src_, tgt_)\n",
    "                edit_no_space = get_edit(src_, [x.replace(' ','') for x in tgt_])\n",
    "                \n",
    "                edit = edit_no_space + 0.1 * (edit_all - edit_no_space)\n",
    "\n",
    "                if src_first:\n",
    "                    # split on target\n",
    "                    return {'src': src_, 'tgt': tgt_,\n",
    "                            'edit': edit}\n",
    "                else:\n",
    "                    # merge on source\n",
    "                    return {'src': tgt_ , 'tgt': src_,\n",
    "                            'edit': edit}\n",
    "        \n",
    "        if plausible == False:\n",
    "            if src_first:\n",
    "                return {'src': src, 'tgt': tgt, 'edit': get_edit(src, tgt)}\n",
    "            else:\n",
    "                return {'src': tgt, 'tgt': src, 'edit': get_edit(src, tgt)}\n",
    "\n",
    "def get_best_edit(edit1, edit2, edit3):\n",
    "    edits = (edit1, edit2, edit3)\n",
    "    # in case of a tie, prefer the basic edit\n",
    "    if edit1['edit'] == edit2['edit'] == edit3['edit']:\n",
    "        return edit1\n",
    "    \n",
    "    edits_w_idx = [(i, x['edit']) for i, x in enumerate(edits)]\n",
    "    \n",
    "    min_edit = min(edits_w_idx, key=lambda x: x[1])[0]\n",
    "    \n",
    "    return edits[min_edit]\n",
    "    \n",
    "    \n",
    "def get_edit(src, tgt):\n",
    "    edit = 0\n",
    "    \n",
    "    for i in range(len(src)):\n",
    "        s, t = normalize_str(src[i]), normalize_str(tgt[i])\n",
    "        edit += edits(s.replace('PNX','') if s != 'NIL' else '',\n",
    "                      t.replace('PNX','') if t != 'NIL' else '')\n",
    "    \n",
    "    return edit\n",
    "    \n",
    "\n",
    "def edits(s1, s2):\n",
    "    return editdistance.distance(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b9238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd82d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_fix(align, seq_bug):\n",
    "    src = []\n",
    "    tgt = []\n",
    "    start = 0\n",
    "\n",
    "    for bug in seq_bug:\n",
    "        src_tokens, tgt_tokens = consruct_clean_src_tgt(align[start: bug.start + 1])\n",
    "        src += src_tokens\n",
    "        tgt += tgt_tokens\n",
    "    \n",
    "        p_src, p_tgt = construct_src_tgt(bug)\n",
    "        _p_src, _p_tgt = perfect_align(p_src, p_tgt)\n",
    "        \n",
    "        src += _p_src\n",
    "        tgt +=  _p_tgt\n",
    "        \n",
    "        start = bug.end\n",
    "\n",
    "\n",
    "    src_tokens, tgt_tokens = consruct_clean_src_tgt(align[start: ])\n",
    "    src += src_tokens\n",
    "    tgt += tgt_tokens\n",
    "    \n",
    "    assert len(src) == len(tgt)\n",
    "    return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "539462f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_alignment(alignment):\n",
    "    clean_alignment = []\n",
    "    for i, align in enumerate(alignment):\n",
    "        seq_bug = capture_bug(align)\n",
    "\n",
    "        if len(seq_bug) == 0:\n",
    "            src, tgt = consruct_clean_src_tgt(align)\n",
    "            \n",
    "            clean_alignment.append({'src': src, 'tgt' : tgt})\n",
    "        \n",
    "        else:\n",
    "            src, tgt = bug_fix(align, seq_bug)\n",
    "            clean_alignment.append({'src': src, 'tgt': tgt})\n",
    "    \n",
    "    return clean_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c2e0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(alignment, path):\n",
    "    with open(path, mode='w') as f:\n",
    "        f.write('SOURCE\\tTARGET')\n",
    "        f.write('\\n')\n",
    "        for example in alignment:\n",
    "            for s, t in zip(example['src'], example['tgt']):\n",
    "                s = s.replace('PNX', '').replace('NIL', '')\n",
    "                t = t.replace('PNX', '').replace('NIL', '')\n",
    "\n",
    "                f.write(f'{s}\\t{t}')\n",
    "                f.write('\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc1e9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_alignment = read_alignment('/scratch/ba63/gec/data/ZAEBUC-v1.0/data/'\\\n",
    "#                                  'ar/dev/dev.alignment.pnx')\n",
    "# src = read_data('/scratch/ba63/gec/data/ZAEBUC-v1.0/data/ar/dev/dev.sent.raw.pnx.tok.ced')\n",
    "# cor = read_data('/scratch/ba63/gec/data/ZAEBUC-v1.0/data/ar/dev/dev.sent.cor.pnx.tok.ced')\n",
    "\n",
    "# clean_alignment = post_process_alignment(basic_alignment)\n",
    "# write_data(clean_alignment, 'bashar_alignment_zaebuc.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c8ab6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_alignment = read_alignment('/scratch/ba63/gec/data/QALB-0.9.1-Dec03-2021-SharedTasks/'\\\n",
    "                                 'data/2014/tune/tune.alignment.pnx')\n",
    "src = read_data('/scratch/ba63/gec/data/QALB-0.9.1-Dec03-2021-SharedTasks/data/'\\\n",
    "                '2014/tune/QALB-2014-L1-Tune.sent.no_ids.clean.ced')\n",
    "cor = read_data('/scratch/ba63/gec/data/QALB-0.9.1-Dec03-2021-SharedTasks/data/'\\\n",
    "                '2014/tune/QALB-2014-L1-Tune.cor.no_ids.ced')\n",
    "\n",
    "# clean_alignment = post_process_alignment(basic_alignment)\n",
    "# write_data(clean_alignment, 'bashar_alignment_qalb14.txt') # 741, 2, 780\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a93b7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_alignment = post_process_alignment(basic_alignment)\n",
    "# write_data(clean_alignment, 'bashar_alignment_qalb14.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e5d196e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['هل', 'هل', 'KEEP', (1, 1)],\n",
       " ['يوجد', 'يوجد', 'KEEP', (2, 2)],\n",
       " ['سفاح', 'سفاح', 'KEEP', (3, 3)],\n",
       " ['ومجرم', 'ومجرم', 'KEEP', (4, 4)],\n",
       " ['بهذا', 'بهذا', 'KEEP', (5, 5)],\n",
       " ['الشكل', 'الشكل', 'KEEP', (6, 6)],\n",
       " ['في', 'في', 'KEEP', (7, 7)],\n",
       " ['العالم', 'العالم', 'KEEP', (8, 8)],\n",
       " ['الان', 'الآن', 'REPLACE', (9, 9)],\n",
       " ['PNX؟', 'PNX؟', 'KEEP', (10, 10)],\n",
       " ['لا', 'لا', 'KEEP', (11, 11)],\n",
       " ['يتوانون', 'يتوانون', 'KEEP', (12, 12)],\n",
       " ['عن', 'عن', 'KEEP', (13, 13)],\n",
       " ['قصف', 'قصف', 'KEEP', (14, 14)],\n",
       " ['المدنيين', 'المدنيين', 'KEEP', (15, 15)],\n",
       " ['بالمدافع', 'بالمدافع', 'KEEP', (16, 16)],\n",
       " ['PNX،', 'INSERT', (None, 17)],\n",
       " ['والدبابات', 'والدبابات', 'KEEP', (17, 18)],\n",
       " ['PNX،', 'INSERT', (None, 19)],\n",
       " ['والزوارق', 'والزوارق', 'KEEP', (18, 20)],\n",
       " ['الحربية', 'الحربية', 'KEEP', (19, 21)],\n",
       " ['PNX،', 'PNX.', 'REPLACE', (20, 22)],\n",
       " ['الى', 'إلى', 'REPLACE', (21, 23)],\n",
       " ['متى', 'متى', 'KEEP', (22, 24)],\n",
       " ['سيبقى', 'سيبقى', 'KEEP', (23, 25)],\n",
       " ['العالم', 'العالم', 'KEEP', (24, 26)],\n",
       " ['يعطي', 'يعطي', 'KEEP', (25, 27)],\n",
       " ['مهلة', 'مهلة', 'KEEP', (26, 28)],\n",
       " ['لهذا', 'لهذا', 'KEEP', (27, 29)],\n",
       " ['المجرم', 'المجرم', 'KEEP', (28, 30)],\n",
       " ['واعوانه', 'وأعوانه', 'REPLACE', (29, 31)],\n",
       " ['PNX؟', 'PNX؟', 'KEEP', (30, 32)],\n",
       " ['لقد', 'لقد', 'KEEP', (31, 33)],\n",
       " ['سقط', 'سقط', 'KEEP', (32, 34)],\n",
       " ['القناع', 'القناع', 'KEEP', (33, 35)],\n",
       " ['عن', 'عن', 'KEEP', (34, 36)],\n",
       " ['المتآمرين', 'المتآمرين', 'KEEP', (35, 37)],\n",
       " ['والخونة', 'والخونة', 'KEEP', (36, 38)],\n",
       " ['PNX،', 'INSERT', (None, 39)],\n",
       " ['ولا', 'INSERT', (None, 40)],\n",
       " ['ولانطلب', 'نطلب', 'REPLACE', (37, 41)],\n",
       " ['العون', 'العون', 'KEEP', (38, 42)],\n",
       " ['إلا', 'إلا', 'KEEP', (39, 43)],\n",
       " ['من', 'من', 'KEEP', (40, 44)],\n",
       " ['الله', 'الله', 'KEEP', (41, 45)],\n",
       " ['عز', 'عز', 'KEEP', (42, 46)],\n",
       " ['وجل', 'وجل', 'KEEP', (43, 47)],\n",
       " ['ان', 'أن', 'REPLACE', (44, 48)],\n",
       " ['يزيح', 'يزيح', 'KEEP', (45, 49)],\n",
       " ['عنا', 'عنا', 'KEEP', (46, 50)],\n",
       " ['هذا', 'هذا', 'KEEP', (47, 51)],\n",
       " ['الطاغية', 'الطاغية', 'KEEP', (48, 52)],\n",
       " ['واعوانه', 'وأعوانه', 'REPLACE', (49, 53)],\n",
       " ['قبل', 'قبل', 'KEEP', (50, 54)],\n",
       " ['حلول', 'حلول', 'KEEP', (51, 55)],\n",
       " ['العيد', 'العيد', 'KEEP', (52, 56)],\n",
       " ['يارب', 'يا', 'REPLACE', (53, 57)],\n",
       " ['يارب', 'رب', 'REPLACE', (54, 58)],\n",
       " ['PNX،', 'INSERT', (None, 59)],\n",
       " ['يارب', 'يا', 'REPLACE', (55, 60)],\n",
       " ['رب', 'INSERT', (None, 61)],\n",
       " ['PNX،', 'INSERT', (None, 62)],\n",
       " ['يا', 'INSERT', (None, 63)],\n",
       " ['رب', 'INSERT', (None, 64)],\n",
       " ['PNX.', 'INSERT', (None, 65)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_alignment[741]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80665945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 11, 'end': 15, 'ops': {12: ['محكمه', 'محكمة', 'REPLACE', (13, 13)], 13: ['PNX،', 'INSERT', (None, 14)], 14: ['فهوا', 'فهو', 'REPLACE', (14, 15)]}}\n",
      "['محكمه', 'NIL', 'فهوا']\n",
      "['محكمة', 'PNX،', 'فهو']\n",
      "\n",
      "========\n",
      "['محكمه', 'NIL', 'فهوا']\n",
      "['محكمة', 'PNX،', 'فهو']\n",
      "========\n",
      "\n",
      "{'start': 15, 'end': 18, 'ops': {16: ['PNX.', 'INSERT', (None, 17)], 17: ['ان', 'إن', 'REPLACE', (16, 18)]}}\n",
      "['NIL', 'ان']\n",
      "['PNX.', 'إن']\n",
      "\n",
      "========\n",
      "['NIL', 'ان']\n",
      "['PNX.', 'إن']\n",
      "========\n",
      "\n",
      "{'start': 22, 'end': 25, 'ops': {23: ['PNX،', 'INSERT', (None, 24)], 24: ['واقول', 'وأقول', 'REPLACE', (22, 25)]}}\n",
      "['NIL', 'واقول']\n",
      "['PNX،', 'وأقول']\n",
      "\n",
      "========\n",
      "['NIL', 'واقول']\n",
      "['PNX،', 'وأقول']\n",
      "========\n",
      "\n",
      "{'start': 27, 'end': 30, 'ops': {28: ['PNX،', 'INSERT', (None, 29)], 29: ['او', 'أو', 'REPLACE', (26, 30)]}}\n",
      "['NIL', 'او']\n",
      "['PNX،', 'أو']\n",
      "\n",
      "========\n",
      "['NIL', 'او']\n",
      "['PNX،', 'أو']\n",
      "========\n",
      "\n",
      "{'start': 31, 'end': 34, 'ops': {32: ['PNX،', 'INSERT', (None, 33)], 33: ['ان', 'أن', 'REPLACE', (29, 34)]}}\n",
      "['NIL', 'ان']\n",
      "['PNX،', 'أن']\n",
      "\n",
      "========\n",
      "['NIL', 'ان']\n",
      "['PNX،', 'أن']\n",
      "========\n",
      "\n",
      "{'start': 34, 'end': 38, 'ops': {35: ['وطغمتهو', 'وطغمته', 'REPLACE', (31, 36)], 36: ['عثو', 'عثوا', 'REPLACE', (32, 37)], 37: ['فساد', 'فسادا', 'REPLACE', (33, 38)]}}\n",
      "['وطغمتهو', 'عثو', 'فساد']\n",
      "['وطغمته', 'عثوا', 'فسادا']\n",
      "\n",
      "========\n",
      "['وطغمتهو', 'عثو', 'فساد']\n",
      "['وطغمته', 'عثوا', 'فسادا']\n",
      "========\n",
      "\n",
      "{'start': 40, 'end': 43, 'ops': {41: ['عام', 'عاما', 'REPLACE', (37, 42)], 42: ['PNX،', 'INSERT', (None, 43)]}}\n",
      "['عام', 'NIL']\n",
      "['عاما', 'PNX،']\n",
      "\n",
      "========\n",
      "['عام', 'NIL']\n",
      "['عاما', 'PNX،']\n",
      "========\n",
      "\n",
      "{'start': 43, 'end': 54, 'ops': {44: ['ولاسلام', 'والإسلام', 'REPLACE', (39, 45)], 45: ['اي', 'أي', 'REPLACE', (40, 46)], 46: ['الاسد', 'الأسد', 'REPLACE', (41, 47)], 47: ['PNX،', 'INSERT', (None, 48)], 48: ['حكمات', 'حكمت', 'REPLACE', (42, 49)], 49: ['فافنيت', 'فأفنيت', 'REPLACE', (43, 50)], 50: ['بلاد', 'بلادا', 'REPLACE', (44, 51)], 51: ['وخيران', 'وخيرا', 'REPLACE', (45, 52)], 52: ['PNX.', 'INSERT', (None, 53)], 53: ['اقول', 'أقول', 'REPLACE', (46, 54)]}}\n",
      "['ولاسلام', 'اي', 'الاسد', 'NIL', 'حكمات', 'فافنيت', 'بلاد', 'وخيران', 'NIL', 'اقول']\n",
      "['والإسلام', 'أي', 'الأسد', 'PNX،', 'حكمت', 'فأفنيت', 'بلادا', 'وخيرا', 'PNX.', 'أقول']\n",
      "\n",
      "========\n",
      "['ولاسلام', 'اي', 'الاسد', 'NIL', 'حكمات', 'فافنيت', 'بلاد', 'وخيران', 'اقول']\n",
      "['والإسلام', 'أي', 'الأسد', 'PNX،', 'حكمت', 'فأفنيت', 'بلادا', 'وخيرا PNX.', 'أقول']\n",
      "========\n",
      "\n",
      "{'start': 58, 'end': 62, 'ops': {59: ['PNX:', 'INSERT', (None, 60)], 60: ['اتقي', 'اتق', 'REPLACE', (52, 61)], 61: ['لله', 'الله', 'REPLACE', (53, 62)]}}\n",
      "['NIL', 'اتقي', 'لله']\n",
      "['PNX:', 'اتق', 'الله']\n",
      "\n",
      "========\n",
      "['NIL', 'اتقي', 'لله']\n",
      "['PNX:', 'اتق', 'الله']\n",
      "========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bug_ex = capture_bug(basic_alignment[2])\n",
    "for bug in bug_ex:\n",
    "    print(bug)\n",
    "\n",
    "    src, tgt = construct_src_tgt(bug)\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    print()\n",
    "#     print(f'Basic edit: {get_basic_edit(src, tgt)}')\n",
    "    print('========')\n",
    "#     import pdb; pdb.set_trace()\n",
    "    new_src, new_tgt = perfect_align(src, tgt)\n",
    "    \n",
    "    print(new_src)\n",
    "    print(new_tgt)\n",
    "    print('========')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446535d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (misc)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
