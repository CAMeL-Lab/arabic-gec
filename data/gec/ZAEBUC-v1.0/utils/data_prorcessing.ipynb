{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0134d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path) as f:\n",
    "        return [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e179ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_id_map(splits):\n",
    "    id_split_map = {}\n",
    "    for line in splits:\n",
    "        id, split, cefr = line.split('\\t')\n",
    "        id_split_map[id] = (split, cefr)\n",
    "    return id_split_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012219d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_splits(data, id_split_map, output_path):\n",
    "    id = None\n",
    "    with open(output_path, mode='w') as f:\n",
    "        f.write('Document\\tRaw\\tCorrected\\tOperation\\tCEFR\\tSplit\\n')\n",
    "        for line in data:\n",
    "            doc_info, raw, corrected, op = line.split('\\t')\n",
    "            doc_id = doc_info.split('.')[0].split('-')[-1]\n",
    "            split, cefr = id_split_map[doc_id]\n",
    "            if doc_id != id and id != None:\n",
    "                f.write('\\n')\n",
    "            f.write(f'{doc_info}\\t{raw}\\t{corrected}\\t{op}\\t{cefr}\\t{split}\\n')\n",
    "            id = doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ad7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplit_data = read_data('AR-all.alignment-FINAL.tsv')[1:]\n",
    "splits = read_data('ar_splits.txt')\n",
    "id_split_map = create_split_id_map(splits)\n",
    "add_splits(unsplit_data, id_split_map, output_path='AR-all.alignment-FINAL.splits.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e08bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsplit_data = read_data('EN-all.alignment-FINAL.tsv')[1:]\n",
    "splits = read_data('en_splits.txt')\n",
    "id_split_map = create_split_id_map(splits)\n",
    "add_splits(unsplit_data, id_split_map, output_path='EN-all.alignment-FINAL.splits.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce8cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_data(data):\n",
    "    ex = []\n",
    "    train_all_examples = []\n",
    "    \n",
    "    dev_all_examples = []\n",
    "    \n",
    "    test_all_examples = []\n",
    "    \n",
    "    for line in data:\n",
    "        if line:\n",
    "            doc_info, raw, corrected, op, cefr, split = line.split('\\t')\n",
    "            ex.append((doc_info, raw, corrected, cefr, op))\n",
    "        else:\n",
    "            if split == 'Train':\n",
    "                train_all_examples.append(ex)\n",
    "            elif split == 'Dev':\n",
    "                dev_all_examples.append(ex)\n",
    "            elif split == 'Test':\n",
    "                test_all_examples.append(ex)\n",
    "            \n",
    "            ex = []\n",
    "    \n",
    "    # adding the last example\n",
    "    if ex:\n",
    "        if split == 'Train':\n",
    "            train_all_examples.append(ex)\n",
    "        elif split == 'Dev':\n",
    "            dev_all_examples.append(ex)\n",
    "        elif split == 'Test':\n",
    "            test_all_examples.append(ex)\n",
    "\n",
    "    return train_all_examples, dev_all_examples, test_all_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c3c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_collated_data(collated_data, output_path):\n",
    "    with open(output_path, mode='w') as f:\n",
    "        f.write('Document\\tRaw\\tCorrected\\tCEFR\\tOperation\\n')\n",
    "        for ex in collated_data:\n",
    "            for sent in ex:\n",
    "                doc_info, raw, correct, cefr, op = sent\n",
    "                f.write(f'{doc_info}\\t{raw}\\t{correct}\\t{cefr}\\t{op}\\n')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0928263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_splits = read_data('AR-all.alignment-FINAL.splits.tsv')[1:]\n",
    "train_examples, dev_examples, test_examples = collate_data(data_with_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988257c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_collated_data(train_examples, 'data/ar/train/train.tokens')\n",
    "write_collated_data(dev_examples, 'data/ar/dev/dev.tokens')\n",
    "write_collated_data(test_examples, 'data/ar/test/test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53650e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005166dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcfb2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_splits = read_data('EN-all.alignment-FINAL.splits.tsv')[1:]\n",
    "train_examples, dev_examples, test_examples = collate_data(data_with_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c706beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_collated_data(train_examples, 'data/en/train/train.tokens')\n",
    "write_collated_data(dev_examples, 'data/en/dev/dev.tokens')\n",
    "write_collated_data(test_examples, 'data/en/test/test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7988f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (misc)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
